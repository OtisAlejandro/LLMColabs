{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "Lrm840I33hkC"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OtisAlejandro/LLMColabs/blob/main/Otis'_Colab_GPU_(EXPERIMENTAL).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX9y5koxa58q"
      },
      "source": [
        "# Welcome to Otis' Colab GPU Edition!\n",
        "Hello everyone and thank you for choosing my colab. If you're here for one of the mixed models like Shygmalion, then just select it in the second cell, along with the provider and version. Whichever version you select doesn't matter, because the mixed models use United and it will switch automatically. **DISCLAIMER: This colab contains all of the tested/untested models I have. You may experience instability or errors with some models, which is out of my control. If you are looking for the stable, official version of my colab, you can find the [link here.](https://colab.research.google.com/drive/1idSTjNVwCoyJ_nljSoFL2_gjeULcGlKg?usp=sharing)**\n",
        "\n",
        "If you'd like more information about Kobold, you can read their Github's readme file here: https://github.com/KoboldAI/KoboldAI-Client/blob/main/readme.md\n",
        "\n",
        "TPUs are currently unavailable, but I'll be making a TPU edition as well for the larger models.\n",
        "\n",
        "If you have any questions or concerns, feel free to DM me @Otis#9664 or ping me in the [PygmalionAI Discord.](discord.gg/pygmalionai)\n",
        "\n",
        "---\n",
        "## How to load the KoboldAI UI\n",
        "1. Although I designed the colab for desktop users, it should not have a problem on mobile as long as you are using desktop mode. If you're on mobile, tap the play button on the first cell so your Colab doesn't get shut down for inactivity.\n",
        "2. Next, select your desired model. If you want more information on a specific model, there is a table with basic information about each of them.\n",
        "3. Click theplay button on the KoboldAI cell next to \"<-- Click this to start the UI\".\n",
        "4. If you get a message saying no accelerator is available/you ran out of runtime, you are gonna need to wait 24 hours for your cooldown to reset, or try again.\n",
        "5. After everything has loaded, you will get a link to the KoboldAI UI that you can also copy into TavernAI's API and use there. If you get a warning for the localtunnel link, just acknowledge it and proceed to the page. If you get a 1033 error with the Cloudflare link, wait 1 minute and refresh the error page.\n",
        "\n",
        "---\n",
        "\n",
        "Further down the page you can find descriptions of the models, and tips to get the most out of your Google Colab experience.\n",
        "\n",
        "Make sure to keep this page open while you are using KoboldAI, and check back regularly to see if you got a Captcha. Failure to complete the captcha's in time can result in termination of your session or a lower priority towards the TPUs.\n",
        "\n",
        "Firefox users need to disable the enhanced tracking protection or use a different browser in order to be able to use Google Colab without errors (This is not something we can do anything about, the cookie blocker breaks the Google Drive integration because it uses different domains).\n",
        "\n",
        "[Credit to the original ColabKobold notebook!](https://colab.research.google.com/github/KoboldAI/KoboldAI-Client/blob/main/colab/GPU.ipynb?authuser=1#scrollTo=lVftocpwCoYw)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DISCLAIMER:** This notebook contains experimental models. You may experience instability or trouble running certain models. This is completely out of my control. As always, if you have any questions or concerns, my DMs are always open @Otis#9664 :)"
      ],
      "metadata": {
        "id": "otIfhRa9denr"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewkXkyiFP2Hq"
      },
      "source": [
        "#@title <-- Tap this if you play on Mobile { display-mode: \"form\" }\n",
        "%%html\n",
        "<b>Press play on the music player to keep the tab alive, then start KoboldAI below (Uses only 13MB of data)</b><br/>\n",
        "<audio src=\"https://raw.githubusercontent.com/KoboldAI/KoboldAI-Client/main/colab/silence.m4a\" controls>"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVftocpwCoYw"
      },
      "source": [
        "#@title <b><-- Select your model below and then click this to start KoboldAI</b>\n",
        "#@markdown You can find a description of the models below along with instructions on how to start KoboldAI.\n",
        "\n",
        "Model = \"Nerys V2 6B\" #@param [\"Nerys V2 6B\", \"Erebus 6B\", \"Skein 6B\", \"Janeway 6B\", \"Adventure 6B\", \"Lit V2 6B\", \"Lit 6B\", \"Shinen 6B\", \"Nerys 2.7B\", \"AID 2.7B\", \"Erebus 2.7B\", \"Janeway 2.7B\", \"Picard 2.7B\", \"Horni LN 2.7B\", \"Horni 2.7B\", \"Shinen 2.7B\", \"OPT 2.7B\", \"Fairseq Dense 2.7B\", \"Neo 2.7B\", \"Pygway 6B\", \"Nerybus 6.7B\", \"Pygway v8p4\", \"PPO-Janeway 6B\", \"PPO Shygmalion 6B\", \"LLaMA 7B\", \"Janin-GPTJ\", \"Javelin-GPTJ\", \"Javelin-R\", \"Janin-R\", \"Javalion-R\", \"Javalion-GPTJ\", \"Javelion-6B\", \"GPT-J-Pyg-PPO-6B\", \"ppo_hh_pythia-6B\", \"ppo_hh_gpt-j\", \"GPT-J-Pyg_PPO-6B\", \"GPT-J-Pyg_PPO-6B-Dev-V8p4\", \"Dolly_GPT-J-6b\", \"Dolly_Pyg-6B\", \"Shygmolly\"] {allow-input: true}\n",
        "Version = \"Official\" #@param [\"Official\", \"United\"] {allow-input: true}\n",
        "Provider = \"Cloudflare\" #@param [\"Localtunnel\", \"Cloudflare\"]\n",
        "use_google_drive = True #@param {type:\"boolean\"}\n",
        "\n",
        "!nvidia-smi\n",
        "from google.colab import drive\n",
        "if use_google_drive:\n",
        "  drive.mount('/content/drive/')\n",
        "else:\n",
        "  import os\n",
        "  if not os.path.exists(\"/content/drive\"):\n",
        "    os.mkdir(\"/content/drive\")\n",
        "  if not os.path.exists(\"/content/drive/MyDrive/\"):\n",
        "    os.mkdir(\"/content/drive/MyDrive/\")\n",
        "\n",
        "Revision = \"\"\n",
        "\n",
        "if Model == \"Nerys V2 6B\":\n",
        "  Model = \"KoboldAI/OPT-6B-nerys-v2\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Erebus 6B\":\n",
        "  Model = \"KoboldAI/OPT-6.7B-Erebus\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Skein 6B\":\n",
        "  Model = \"KoboldAI/GPT-J-6B-Skein\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Janeway 6B\":\n",
        "  Model = \"KoboldAI/GPT-J-6B-Janeway\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Adventure 6B\":\n",
        "  Model = \"KoboldAI/GPT-J-6B-Adventure\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Lit V2 6B\":\n",
        "  Model = \"hakurei/litv2-6B-rev3\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Lit 6B\":\n",
        "  Model = \"hakurei/lit-6B\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Shinen 6B\":\n",
        "  Model = \"KoboldAI/GPT-J-6B-Shinen\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Nerys 2.7B\":\n",
        "  Model = \"KoboldAI/fairseq-dense-2.7B-Nerys\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Erebus 2.7B\":\n",
        "  Model = \"KoboldAI/OPT-2.7B-Erebus\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Janeway 2.7B\":\n",
        "  Model = \"KoboldAI/GPT-Neo-2.7B-Janeway\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Picard 2.7B\":\n",
        "  Model = \"KoboldAI/GPT-Neo-2.7B-Picard\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"AID 2.7B\":\n",
        "  Model = \"KoboldAI/GPT-Neo-2.7B-AID\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Horni LN 2.7B\":\n",
        "  Model = \"KoboldAI/GPT-Neo-2.7B-Horni-LN\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Horni 2.7B\":\n",
        "  Model = \"KoboldAI/GPT-Neo-2.7B-Horni\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Shinen 2.7B\":\n",
        "  Model = \"KoboldAI/GPT-Neo-2.7B-Shinen\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Fairseq Dense 2.7B\":\n",
        "  Model = \"KoboldAI/fairseq-dense-2.7B\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"OPT 2.7B\":\n",
        "  Model = \"facebook/opt-2.7b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Neo 2.7B\":\n",
        "  Model = \"EleutherAI/gpt-neo-2.7B\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Pygway 6B\":\n",
        "  Model = \"TehVenom/PPO_Pygway-6b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Nerybus 6.7B\":\n",
        "  Model = \"KoboldAI/OPT-6.7B-Nerybus-Mix\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Pygway v8p4\":\n",
        "  Model = \"TehVenom/PPO_Pygway-V8p4_Dev-6b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"PPO-Janeway 6B\":\n",
        "  Model = \"TehVenom/PPO_Janeway-6b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"PPO Shygmalion 6B\":\n",
        "  Model = \"TehVenom/PPO_Shygmalion-6b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"LLaMA 7B\":\n",
        "  Model = \"decapoda-research/llama-7b-hf\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Janin-GPTJ\":\n",
        "  Model = \"digitous/Janin-GPTJ\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Javelin-GPTJ\":\n",
        "  Model = \"digitous/Javelin-GPTJ\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Javelin-R\":\n",
        "  Model = \"digitous/Javelin-R\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Janin-R\":\n",
        "  Model = \"digitous/Janin-R\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Javalion-R\":\n",
        "  Model = \"digitous/Javalion-R\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Javalion-GPTJ\":\n",
        "  Model = \"digitous/Javalion-GPTJ\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Javelion-6B\":\n",
        "  Model = \"Cohee/Javelion-6b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"GPT-J-Pyg-PPO-6B\":\n",
        "  Model = \"TehVenom/GPT-J-Pyg_PPO-6B\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"ppo_hh_pythia-6B\":\n",
        "  Model = \"reciprocate/ppo_hh_pythia-6B\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"ppo_hh_gpt-j\":\n",
        "  Model = \"reciprocate/ppo_hh_gpt-j\"\n",
        "  path= \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Alpaca-7B\":\n",
        "  Model = \"chainyo/alpaca-lora-7b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"LLaMA 4-bit\":\n",
        "  Model = \"decapoda-research/llama-13b-hf-int4\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"GPT-J-Pyg_PPO-6B\":\n",
        "  Model = \"TehVenom/GPT-J-Pyg_PPO-6B\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"GPT-J-Pyg_PPO-6B-Dev-V8p4\":\n",
        "  Model = \"TehVenom/GPT-J-Pyg_PPO-6B-Dev-V8p4\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Dolly_GPT-J-6b\":\n",
        "  Model = \"TehVenom/Dolly_GPT-J-6b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Dolly_Pyg-6B\":\n",
        "  Model = \"TehVenom/AvgMerge_Dolly-Pygmalion-6b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "elif Model == \"Shygmolly\":\n",
        "  Model = \"TehVenom/Dolly_Shygmalion-6b\"\n",
        "  path = \"\"\n",
        "  download = \"\"\n",
        "  Version = \"United\"\n",
        "  \n",
        "if Provider == \"Localtunnel\":\n",
        "  tunnel = \"--localtunnel yes\"\n",
        "else:\n",
        "  tunnel = \"\"\n",
        "  \n",
        "#UNCOMMENT THE THREE BELOW LINES IF YOU ARE RUNNING LLAMA\n",
        "#!wget https://koboldai.org/ckds -O - | bash /dev/stdin -g United --init only\n",
        "#!pip install --upgrade --force-reinstall git+https://github.com/zphang/transformers@68d640f7c368bcaaaecfc678f11908ebbd3d6176\n",
        "#!wget https://koboldai.org/ckds -O - | bash /dev/stdin -m $Model -g $Version $Revision $tunnel --init skip\n",
        "\n",
        "#COMMENT BELOW LINE IF YOU ARE RUNNING LLAMA\n",
        "!wget https://koboldai.org/ckds -O - | bash /dev/stdin -m $Model -g $Version $Revision $tunnel\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPU Edition Model Descriptions\n",
        "| Model | Style | Description |\n",
        "| --- | --- | --- |\n",
        "| [Nerys](https://huggingface.co/KoboldAI/fairseq-dense-2.7B-Nerys) by Mr Seeker | Novel/Adventure | Nerys is a hybrid model based on Pike (A newer Janeway), on top of the Pike dataset you also get some Light Novels, Adventure mode support and a little bit of Shinen thrown in the mix. The end result is a very diverse model that is heavily biased towards SFW novel writing, but one that can go beyond its novel training and make for an excellent adventure model to. Adventure mode is best played from a second person perspective, but can be played in first or third person as well. Novel writing can be done best from the first or third person. |\n",
        "| [Erebus](https://huggingface.co/KoboldAI/OPT-2.7B-Erebus) by Mr Seeker | NSFW | Erebus is our community's flagship NSFW model, being a combination of multiple large datasets that include Literotica, Shinen and erotic novels from Nerys and featuring thourough tagging support it covers the vast majority of erotic writing styles. This model is capable of replacing both the Lit and Shinen models in terms of content and style and has been well received as (one of) the best NSFW models out there. If you wish to use this model for commercial or non research usage we recommend choosing the 20B version as that one is not subject to the restrictive OPT license. |\n",
        "| [Janeway](https://huggingface.co/KoboldAI/GPT-Neo-2.7B-Janeway) by Mr Seeker | Novel | Janeway is a model created from Picard's dataset combined with a brand new collection of ebooks. This model is trained on 20% more content than Picard and has been trained on literature from various genres. Although the model is mainly focussed on SFW, romantic scenes might involve a degree of nudity. |\n",
        "| [Picard](https://huggingface.co/KoboldAI/GPT-Neo-2.7B-Picard) by Mr Seeker | Novel | Picard is a model trained for SFW Novels based on Neo 2.7B. It is focused on Novel style writing without the NSFW bias. While the name suggests a sci-fi model this model is designed for Novels of a variety of genre's. It is meant to be used in KoboldAI's regular mode. |\n",
        "| [AID](https://huggingface.co/KoboldAI/GPT-Neo-2.7B-AID) by melastacho | Adventure | Also know as Adventure 2.7B this is a clone of the AI Dungeon Classic model and is best known for the epic wackey adventures that AI Dungeon Classic players love. |\n",
        "| [Pygmalion](https://huggingface.co/KoboldAI/GPT-J-6B-Adventure) by PygmalionAI | Chatbot | Pygmalion is a chat model that has been based on a few models that came before it. First the model originates from LitV2, it was then trained by Haru on a chat dataset to create ConvoGPT. ConvoGPT was then trained by PygmalionAI on chat data that contains longer responses and emotions. Making for a higher quality chat experience than you can get from other models such as Erebus that are not directly trained on chatting. |\n",
        "| [Horni LN](https://huggingface.co/KoboldAI/GPT-Neo-2.7B-Horni-LN) by finetune | Novel | This model is based on Horni 2.7B and retains its NSFW knowledge, but was then further biased towards SFW novel stories. If you seek a balance between a SFW Novel model and a NSFW model this model should be a good choice. |\n",
        "| [Horni](https://huggingface.co/KoboldAI/GPT-Neo-2.7B-Horni) by finetune | NSFW | This model is tuned on Literotica to produce a Novel style model biased towards NSFW content. Can still be used for SFW stories but will have a bias towards NSFW content. It is meant to be used in KoboldAI's regular mode. |\n",
        "| [Shinen](https://huggingface.co/KoboldAI/GPT-Neo-2.7B-Shinen) by Mr Seeker | NSFW | Shinen is an alternative to the Horni model designed to be more explicit. If Horni is to tame for you Shinen might produce better results. While it is a Novel model it is unsuitable for SFW stories due to its heavy NSFW bias. Shinen will not hold back. It is meant to be used in KoboldAI's regular mode. |\n",
        "| [OPT](https://huggingface.co/facebook/opt-2.7b) by Metaseq | Generic | OPT is considered one of the best base models as far as content goes, its behavior has the strengths of both GPT-Neo and Fairseq Dense. Compared to Neo duplicate and unnecessary content has been left out, while additional literature was added in similar to the Fairseq Dense model. The Fairseq Dense model however lacks the broader data that OPT does have. The biggest downfall of OPT is its license, which prohibits any commercial usage, or usage beyond research purposes. |\n",
        "| [Fairseq Dense](https://huggingface.co/KoboldAI/fairseq-dense-2.7B) | Generic | Trained by Facebook Researchers this model stems from the MOE research project within Fairseq. This particular version has been converted by us for use in KoboldAI. It is known to be on par with the larger models from EleutherAI and considered as better for pop culture and language tasks. Because the model has never seen a new line (enter) it may perform worse on formatting and paragraphing. Compared to other models the dataset focuses primarily on literature and contains little else. |\n",
        "| [Neo](https://huggingface.co/EleutherAI/gpt-neo-2.7B) by EleutherAI | Generic | This is the base model for all the other 2.7B models, it is best used when you have a use case that we have no other models available for, such as writing blog articles or programming. It can also be a good basis for the experience of some of the softprompts if your softprompt is not about a subject the other models cover. |\n",
        "| [Pygway 6B](https://huggingface.co/TehVenom/PPO_Pygway-6b) by TehVenom | Chatbot | This is a mix between Pygmalion 6B and Janeway, designed especially to carry the coherence and verbosity of Pyg's v8, while having the ERP ability of 6B. |\n",
        "| [Nerybus 6.7B](https://huggingface.co/KoboldAI/OPT-6.7B-Nerybus-Mix) by KoboldAI | Chatbot | A mix between Nerys and Erebus, meant for an adventure style NSFW chat. |\n",
        "| [Pygway v8P4](https://huggingface.co/TehVenom/PPO_Pygway-V8p4_Dev-6b) by TehVenom | Chatbot | This is a mixed model between Janeway 6B and Pygmalion 6B's Dev Branch v8P4. This bot is guided towards a chat-oriented roleplay, and aims to provide the verbosity and creativity of v8, and mitigate the NSFW issues of v8P4 with Janeway. |\n",
        "|[PPO Shygmalion 6B](https://huggingface.co/TehVenom/PPO_Shygmalion-6b) by TehVenom | Chatbot | Shygmalion is one of the more favorited mixed models of the bunch. A mix of Shinen, ppo_HH, and Pygmalion 6B, this model can provide a great ERP experience. If you encounter issues with POV, using bias may solve it. |\n",
        "|[Dolly_Pyg-6B](https://huggingface.co/TehVenom/AvgMerge_Dolly-Pygmalion-6b) by TehVenom | Chatbot | Dolly_Pyg-6B is a merge between LLaMA LoRA Dolly and Pygmalion 6B. Designed for verbosity, crativity, and chat roleplay, this bot can do both NSFW and SFW chatting.\n",
        "| Style     | Description                                                  |\n",
        "| --------- | ------------------------------------------------------------ |\n",
        "| Novel     | For regular story writing, not compatible with Adventure mode or other specialty modes. |\n",
        "| NSFW      | Indicates that the model is strongly biased towards NSFW content and is not suitable for children, work environments or livestreaming. Most NSFW models are also Novel models in nature. |\n",
        "| Adventure | These models are excellent for people willing to play KoboldAI like a Text Adventure game and are meant to be used with Adventure mode enabled. Even if you wish to use it as a Novel style model you should always have Adventure mode on and set it to story. These models typically have a strong bias towards the use of the word You and without Adventure mode enabled break the story flow and write actions on your behalf. |\n",
        "| Generic   | Generic models are not trained towards anything specific, typically used as a basis for other tasks and models. They can do everything the other models can do, but require much more handholding to work properly. Generic models are an ideal basis for tasks that we have no specific model for, or for experiencing a softprompt in its raw form. |"
      ],
      "metadata": {
        "id": "Lrm840I33hkC"
      }
    }
  ]
}